# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../notebooks/ipynb/003_extract_annotation_project.ipynb.

# %% auto 0
__all__ = ['split_array', 'create_detection_yolo', 'write_label', 'extract_task_annotation', 'extract_annotations']

# %% ../../../notebooks/ipynb/003_extract_annotation_project.ipynb 2
from pathlib import Path
from shutil import copy

import numpy as np
import supervision as sv
import torch as t
import yaml
from label_studio_sdk.client import LabelStudio
from label_studio_sdk.converter.brush import decode_rle
from label_studio_sdk.types import Task
from supervision import Detections
from supervision.dataset.formats.yolo import detections_to_yolo_annotations
from tqdm import tqdm

from ..utils import parallel

# %% ../../../notebooks/ipynb/003_extract_annotation_project.ipynb 9
def split_array(
    arr: list, train_ratio: float = 0.7, val_ratio: float = 0.2
) -> tuple[list, list, list]:
    """Split array into train/validation/test sets."""
    n = len(arr)
    train_end = int(n * train_ratio)
    val_end = train_end + int(n * val_ratio)

    return arr[:train_end], arr[train_end:val_end], arr[val_end:]

# %% ../../../notebooks/ipynb/003_extract_annotation_project.ipynb 10
def create_detection_yolo(labels: list[str], frames_path: Path, out_path: Path) -> None:
    # Create directories
    for dir in ["train", "val", "test"]:
        detection_frames_path = out_path / f"{dir}/images"
        detection_labels_path = out_path / f"{dir}/labels"
        detection_frames_path.mkdir(parents=True, exist_ok=True)
        detection_labels_path.mkdir(parents=True, exist_ok=True)

    # Copy existing frames
    all_frames = [file for file in frames_path.glob("*.jpg")]
    train, val, test = split_array(all_frames)
    for split, dir_path in [
        (train, out_path.joinpath("train/images")),
        (val, out_path.joinpath("val/images")),
        (test, out_path.joinpath("test/images")),
    ]:
        for frame in split:
            copy(frame, dir_path.joinpath(frame.name))

    # Write the yaml file
    data_dict = {
        "path": "",
        "train": "",
        "val": "",
        "test": "",
        "names": [{i: label} for i, label in labels],
    }
    yaml_out_path = out_path / "data.yaml"
    yaml_out_path.write_text(yaml.dump(data_dict))

# %% ../../../notebooks/ipynb/003_extract_annotation_project.ipynb 11
def write_label(detections: sv.Detections, out_path: Path, img_shape: tuple) -> None:
    with open(out_path, "w") as f:
        lines = detections_to_yolo_annotations(
            detections=detections,
            image_shape=img_shape,
        )
        f.writelines(lines)

# %% ../../../notebooks/ipynb/003_extract_annotation_project.ipynb 12
def extract_task_annotation(
    task_list: list[Task],
    labels: list[str],
    frame_path: Path,
    job_idx: int = 0,
):
    # Make label maps
    label_map = {k: i for i, k in enumerate(labels)}
    label_map_inv = {v: k for k, v in label_map.items()}

    # Collect all frames for annotation
    frame_to_path_dict = {frame.name: frame for frame in frame_path.rglob("*.jpg")}

    # Query labelsutdio api for annotations
    for task in tqdm(task_list, position=job_idx):
        assert task.annotations is not None
        assert task.storage_filename is not None
        filename = task.storage_filename.split("/")[-1]
        out_file_path = frame_to_path_dict[filename]
        out_file_path = out_file_path.parents[1] / "labels" / filename
        out_file_path = out_file_path.with_suffix("txt")
        if len(task.annotations) == 0:
            # If no annotation is provided then for now skip
            # but in future we will keep the blank frames.txt
            # out_file_path.touch()
            continue

        else:
            print("generating masks")
            masks = []
            classes = []
            scores = []
            img_height = 0
            img_width = 0

            # Collect all annotations for a task
            for anno in task.annotations:
                assert anno["result"] is not None
                for res in anno["result"]:
                    img_width = res["original_width"]
                    img_height = res["original_height"]
                    mask = decode_rle(res["value"]["rle"])
                    mask = np.reshape(mask, [img_height, img_width, 4])[:, :, 3]
                    mask = mask / 255
                    mask = mask.astype(bool)
                    masks.append(mask)
                    classes.append(label_map_inv[res["value"]["brushlabels"][0]])
                    scores.append(1)

            detections = sv.Detections.from_transformers(
                {
                    "scores": t.tensor(scores),
                    "labels": t.tensor(labels),
                    "masks": t.tensor(masks),
                },
                label_map_inv,
            )
            write_label(detections, out_file_path, (img_height, img_width, 0))

# %% ../../../notebooks/ipynb/003_extract_annotation_project.ipynb 13
def extract_annotations(client: LabelStudio, project_id: int, out_path: Path) -> None:
    # Get project
    project = client.projects.get(id=project_id)

    # Get task
    task_pager = client.tasks.list(project=project.id)
    task_list: list[Task] = [task for task in task_pager]

    # Exrtact in parallel
    parallel(task_list, extract_task_annotation, [out_path])
